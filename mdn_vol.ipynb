{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "modified-quick",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import stats\n",
    "import pystan as stan\n",
    "import arviz\n",
    "\n",
    "# Set default figure size\n",
    "plt.rcParams[\"figure.figsize\"] = (15, 10)\n",
    "pd.plotting.register_matplotlib_converters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fifty-reverse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here\"s my minute data for the S&P 500\n",
    "spx_minute = pd.read_csv(\"SPX_1min.csv\", header=0,names=[\"datetime\", \"open\", \"high\", \"low\", \"close\"],\n",
    "                                  index_col=\"datetime\", parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "contemporary-cleaners",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here\"s the function for calculating the 1-min RV, as discussed in my last post\n",
    "def rv_calc(data):\n",
    "    results = {}\n",
    "    \n",
    "    for idx, data in data.groupby(data.index.date):\n",
    "        returns = np.log(data[\"close\"]) - np.log(data[\"close\"].shift(1))\n",
    "        results[idx] = np.sum(returns**2)\n",
    "        \n",
    "    return pd.Series(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "iraqi-mailing",
   "metadata": {},
   "outputs": [],
   "source": [
    "spx_rvar = rv_calc(spx_minute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "directed-commonwealth",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.Connection(\"data.db\")\n",
    "spx_data = pd.read_sql(\"SELECT * FROM prices WHERE ticker='^GSPC'\", conn, index_col=\"date\", parse_dates=\"date\")\n",
    "spx_returns = np.log(spx_data[\"close\"]) - np.log(spx_data[\"close\"].shift(1))\n",
    "spx_returns = spx_returns.dropna()\n",
    "\n",
    "vix_data = pd.read_sql(\"SELECT * FROM prices WHERE ticker='^VIX'\", conn, index_col=\"date\", parse_dates=\"date\")\n",
    "# This puts it into units of daily standard deviation\n",
    "vix = vix_data[\"close\"] / np.sqrt(252) / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "pacific-terror",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lags(series, lags, name=\"x\"):\n",
    "    \"\"\"\n",
    "    Creates a dataframe with lagged values of the given series.\n",
    "    Generates columns named x_{n} which means the value of each row is the value of the original series lagged n times\n",
    "    \"\"\"\n",
    "    result = pd.DataFrame(index=series.index)\n",
    "    result[f\"{name}_t\"] = series\n",
    "    \n",
    "    for n in range(lags):\n",
    "        result[f\"{name}_t-{n+1}\"] = series.shift((n+1))\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "dedicated-bankruptcy",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.DataFrame(index=spx_rvar.index, columns=[\"t+1\", \"t+2\", \"t+3\", \"t+4\", \"t+5\"], dtype=\"float64\")\n",
    "N = 5\n",
    "\n",
    "for x in range(len(spx_rvar) - 5):\n",
    "    y.iloc[x] = spx_rvar.iloc[x+1:x+6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "surrounded-brave",
   "metadata": {},
   "outputs": [],
   "source": [
    "vix_lags = create_lags(vix, 21, name=\"vix\")\n",
    "return_lags = create_lags(spx_returns, 21, name=\"returns\")\n",
    "rv_lags = create_lags(np.sqrt(spx_rvar), 21, name=\"rv\")\n",
    "\n",
    "x = pd.concat([vix_lags, return_lags, rv_lags], axis=1).dropna()\n",
    "y = np.sqrt(y).dropna()\n",
    "\n",
    "common_index = x.index.intersection(y.index)\n",
    "x = x.loc[common_index]\n",
    "y = y.loc[common_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "operational-oakland",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.distributions import Categorical, Normal, Independent, MixtureSameFamily\n",
    "from torch.optim.swa_utils import AveragedModel, SWALR\n",
    "\n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "uniform-potato",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MDN(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, hidden_dim, n_components):\n",
    "        super().__init__()\n",
    "        self.n_components = n_components\n",
    "        # Last layer output dimension rationale:\n",
    "        # Need two parameters for each distributionm thus 2 * n_components.\n",
    "        # Need each of those for each output dimension, thus that multiplication\n",
    "        self.norm_network = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden_dim),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(hidden_dim, 2 * n_components * out_dim)\n",
    "        )\n",
    "        self.cat_network = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden_dim),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(hidden_dim, n_components)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        norm_params = self.norm_network(x)\n",
    "        mean, std = torch.split(norm_params, norm_params.shape[1] // 2, dim=1)\n",
    "        normal = Normal(mean, torch.exp(std))\n",
    "        \n",
    "        cat_params = self.cat_network(x)\n",
    "        cat = Categorical(logits=cat_params)\n",
    "        \n",
    "        return MixtureSameFamily(cat, normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "hourly-wallpaper",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_index = int(len(x) * .75)\n",
    "train_x = torch.Tensor(x.iloc[:test_index].values)\n",
    "train_y = torch.Tensor(y.iloc[:test_index].values)\n",
    "test_x = torch.Tensor(x.iloc[test_index:].values)\n",
    "test_y = torch.Tensor(y.iloc[test_index:].values)\n",
    "\n",
    "in_dim = len(x.columns)\n",
    "out_dim = 5\n",
    "n_components = 10\n",
    "hidden_dim = int(np.mean([in_dim, 2 * n_components * out_dim]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "mediterranean-animation",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`mixture_distribution component` (10) does not equal `component_distribution.batch_shape[-1]` (50)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-222-a3088383a165>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SystemsTrading/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-220-162ffdea96f9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mcat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCategorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcat_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mMixtureSameFamily\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/SystemsTrading/venv/lib/python3.8/site-packages/torch/distributions/mixture_same_family.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, mixture_distribution, component_distribution, validate_args)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mkc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_component_distribution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mkc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mkm\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mkc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             raise ValueError(\"`mixture_distribution component` ({0}) does not\"\n\u001b[0m\u001b[1;32m     81\u001b[0m                              \u001b[0;34m\" equal `component_distribution.batch_shape[-1]`\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                              \" ({1})\".format(km, kc))\n",
      "\u001b[0;31mValueError\u001b[0m: `mixture_distribution component` (10) does not equal `component_distribution.batch_shape[-1]` (50)"
     ]
    }
   ],
   "source": [
    "model = MDN(in_dim, out_dim, hidden_dim, n_components)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=.001)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 100, 2)\n",
    "\n",
    "swa_model = AveragedModel(model)\n",
    "swa_start = 750\n",
    "swa_scheduler = SWALR(optimizer, swa_lr=0.001, anneal_epochs=10, anneal_strategy=\"cos\")\n",
    "\n",
    "train_losses = []\n",
    "validation_losses = []\n",
    "for epoch in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(train_x)\n",
    "\n",
    "    train_loss = -output.log_prob(train_y).sum()\n",
    "    train_losses.append(train_loss.detach())\n",
    "    \n",
    "    test_loss = -model(test_x).log_prob(test_y).sum()\n",
    "    validation_losses.append(test_loss.detach())\n",
    "    \n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch > swa_start:\n",
    "        swa_model.update_parameters(model)\n",
    "        swa_scheduler.step()\n",
    "    else:\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjacent-organ",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
